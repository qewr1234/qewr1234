Info
Hi! I'm Yujun ğŸ‘‹
Computer Science student interested in Deep Learning and Computer Vision.
Deep Learning Computer Vision Segmentation Depth Estimation VLA Time Series

â€¢ Competitions
<table>
  <tr>
    <th>#</th>
    <th>Date</th>
    <th>Event</th>
    <th>Team</th>
    <th>Result</th>
    <th>Links</th>
  </tr>
  <tr>
    <td>8</td>
    <td>2025</td>
    <td>í¬í•­ê³µëŒ€ ì¼ì‚¬ëŸ‰ ì¶”ì • ëŒ€íšŒ</td>
    <td>Solo</td>
    <td>ğŸ† 7th / 153 (ìš°ìˆ˜ìƒ)</td>
    <td><a href="">GitHub</a></td>
  </tr>
  <tr>
    <td>7</td>
    <td>2025</td>
    <td>LG Aimers 7ê¸° ì˜¤í”„ë¼ì¸ í•´ì»¤í†¤ (ë³¸ì„ )</td>
    <td>Team</td>
    <td>12th / 31</td>
    <td></td>
  </tr>
  <tr>
    <td></td>
    <td>2025</td>
    <td>LG Aimers 7ê¸° ì˜¨ë¼ì¸ í•´ì»¤í†¤ (ì˜ˆì„ )</td>
    <td>Team</td>
    <td>25th / 817 (Top 3%)</td>
    <td></td>
  </tr>
  <tr>
    <td>6</td>
    <td>2025</td>
    <td>ìŠ¤ë§ˆíŠ¸ í•´ìš´ë¬¼ë¥˜ x AI ë¯¸ì…˜ ì±Œë¦°ì§€ : ì´ìƒì‹ í˜¸ ê°ì§€ ê¸°ë°˜ ë¹„ì •ìƒ ì‘ë™ ì§„ë‹¨</td>
    <td>Solo</td>
    <td>-</td>
    <td></td>
  </tr>
  <tr>
    <td>5</td>
    <td>2025</td>
    <td>ìŠ¤ë§ˆíŠ¸ í•´ìš´ë¬¼ë¥˜ x AI ë¯¸ì…˜ ì±Œë¦°ì§€ : ìŠ¤ë§ˆíŠ¸ í•­ë§Œ AGV ê²½ë¡œ ìµœì í™”</td>
    <td>Solo</td>
    <td>-</td>
    <td></td>
  </tr>
  <tr>
    <td>4</td>
    <td>2025</td>
    <td>í† ìŠ¤ NEXT ML CHALLENGE : ê´‘ê³  í´ë¦­ ì˜ˆì¸¡(CTR) ëª¨ë¸ ê°œë°œ</td>
    <td>Solo</td>
    <td>261st / 709</td>
    <td></td>
  </tr>
  <tr>
    <td>3</td>
    <td>2025</td>
    <td>Boost Up AI 2025 : ì‹ ì•½ ê°œë°œ ê²½ì§„ëŒ€íšŒ</td>
    <td>Solo</td>
    <td>63rd / 763 (Top 8%)</td>
    <td></td>
  </tr>
  <tr>
    <td>2</td>
    <td>2025</td>
    <td>HAI(í•˜ì´)! - Hecto AI Challenge 2025 : ì¤‘ê³ ì°¨ ì°¨ì¢… ë¶„ë¥˜</td>
    <td>Solo</td>
    <td>90th / 748 (Top 12%)</td>
    <td><a href="">GitHub</a></td>
  </tr>
</table>

â€¢ Projects
<table>
  <tr>
    <th>Project</th>
    <th>Description</th>
    <th>Tech Stack</th>
    <th>Links</th>
  </tr>
  <tr>
    <td>Korean Sign Language & Speech Recognition</td>
    <td>ìˆ˜ì–´ ì§€ë¬¸ì ì¸ì‹ + ìŒì„± ì¸ì‹ í†µí•© ì‹œìŠ¤í…œ</td>
    <td>MediaPipe, Whisper, PyTorch</td>
    <td><a href="">GitHub</a></td>
  </tr>
  <tr>
    <td>Stock Price Prediction</td>
    <td>LSTM + ë‰´ìŠ¤ ê°ì„±ë¶„ì„ ê¸°ë°˜ ì£¼ê°€ ì˜ˆì¸¡</td>
    <td>PyTorch, LSTM, KoBERT</td>
    <td><a href="">GitHub</a></td>
  </tr>
</table>

â€¢ Paper Reading
<table>
  <tr>
    <th>#</th>
    <th>Paper</th>
    <th>Field</th>
    <th>Paper Link</th>
    <th>Notes</th>
  </tr>
  <tr>
    <td>1</td>
    <td>AlexNet</td>
    <td>CNN / Classification</td>
    <td><a href="https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html">NeurIPS 2012</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>2</td>
    <td>VGGNet</td>
    <td>CNN / Classification</td>
    <td><a href="https://arxiv.org/abs/1409.1556">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>3</td>
    <td>ResNet</td>
    <td>CNN / Classification</td>
    <td><a href="https://arxiv.org/abs/1512.03385">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>4</td>
    <td>R-CNN</td>
    <td>Object Detection</td>
    <td><a href="https://arxiv.org/abs/1311.2524">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>5</td>
    <td>Fast R-CNN</td>
    <td>Object Detection</td>
    <td><a href="https://arxiv.org/abs/1504.08083">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>6</td>
    <td>LSTM</td>
    <td>RNN / Sequence</td>
    <td><a href="https://www.bioinf.jku.at/publications/older/2604.pdf">Original</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>7</td>
    <td>XGBoost</td>
    <td>Gradient Boosting</td>
    <td><a href="https://arxiv.org/abs/1603.02754">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>8</td>
    <td>LightGBM</td>
    <td>Gradient Boosting</td>
    <td><a href="https://papers.nips.cc/paper/2017/hash/6449f44a102fde848669bdd9eb6b76fa-Abstract.html">NeurIPS 2017</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>9</td>
    <td>YOLO</td>
    <td>Object Detection</td>
    <td><a href="https://arxiv.org/abs/1506.02640">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>10</td>
    <td>FCN</td>
    <td>Semantic Segmentation</td>
    <td><a href="https://arxiv.org/abs/1411.4038">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>11</td>
    <td>Mask R-CNN</td>
    <td>Instance Segmentation</td>
    <td><a href="https://arxiv.org/abs/1703.06870">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>12</td>
    <td>Panoptic Segmentation</td>
    <td>Panoptic Segmentation</td>
    <td><a href="https://arxiv.org/abs/1801.00868">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>13</td>
    <td>Attention Is All You Need</td>
    <td>Transformer / NLP</td>
    <td><a href="https://arxiv.org/abs/1706.03762">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>14</td>
    <td>Swin Transformer</td>
    <td>Vision Transformer</td>
    <td><a href="https://arxiv.org/abs/2103.14030">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>15</td>
    <td>CLIP</td>
    <td>Vision-Language</td>
    <td><a href="https://arxiv.org/abs/2103.00020">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>16</td>
    <td>SETR</td>
    <td>Transformer Segmentation</td>
    <td><a href="https://arxiv.org/abs/2012.15840">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>17</td>
    <td>Mask2Former</td>
    <td>Universal Segmentation</td>
    <td><a href="https://arxiv.org/abs/2112.01527">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>18</td>
    <td>PointNet++</td>
    <td>3D Point Cloud</td>
    <td><a href="https://arxiv.org/abs/1706.02413">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>19</td>
    <td>RT-1</td>
    <td>Robot VLA</td>
    <td><a href="https://arxiv.org/abs/2212.06817">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>20</td>
    <td>RT-2</td>
    <td>Robot VLA</td>
    <td><a href="https://arxiv.org/abs/2307.15818">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>21</td>
    <td>DINO v1</td>
    <td>Self-Supervised Vision</td>
    <td><a href="https://arxiv.org/abs/2104.14294">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>22</td>
    <td>DINOv2</td>
    <td>Self-Supervised Vision</td>
    <td><a href="https://arxiv.org/abs/2304.07193">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>23</td>
    <td>SAM</td>
    <td>Foundation Model / Segmentation</td>
    <td><a href="https://arxiv.org/abs/2304.02643">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>24</td>
    <td>OpenVLA</td>
    <td>Robot VLA</td>
    <td><a href="https://arxiv.org/abs/2406.09246">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>25</td>
    <td>Zero-shot RIS with Global-Local Context</td>
    <td>Referring Image Segmentation</td>
    <td><a href="https://arxiv.org/abs/2303.17811">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
</table>

â€¢ OS & Tools ğŸ”¨
<img src="https://img.shields.io/badge/Linux-FCC624?style=flat-square&logo=linux&logoColor=black"/> <img src="https://img.shields.io/badge/macOS-000000?style=flat-square&logo=apple&logoColor=white"/> <img src="https://img.shields.io/badge/Ubuntu-E95420?style=flat-square&logo=ubuntu&logoColor=white"/>
<img src="https://img.shields.io/badge/Git-F05032?style=flat-square&logo=git&logoColor=white"/> <img src="https://img.shields.io/badge/GitHub-181717?style=flat-square&logo=github&logoColor=white"/>
<img src="https://img.shields.io/badge/PyTorch-EE4C2C?style=flat-square&logo=pytorch&logoColor=white"/> <img src="https://img.shields.io/badge/ğŸ¤—%20Transformers-FFD21E?style=flat-square"/>
<img src="https://img.shields.io/badge/Python-3776AB?style=flat-square&logo=python&logoColor=white"/> <img src="https://img.shields.io/badge/OpenCV-5C3EE8?style=flat-square&logo=opencv&logoColor=white"/>
