# Info

## Hi! I'm Yujun üëã

Department of Information and Communication Engineering student interested in **Deep Learning** and **Computer Vision**.

`Deep Learning` `Computer Vision` `Segmentation` `Depth Estimation` `VLA` `Time Series`

---

### ‚Ä¢ Competitions

<table>
  <tr>
    <th>#</th>
    <th>Date</th>
    <th>Event</th>
    <th>Team</th>
    <th>Result</th>
    <th>Links</th>
  </tr>
  <tr>
    <td>1</td>
    <td>2025.01</td>
    <td>HAI Hecto AI Challenge 2025 - Ï§ëÍ≥†Ï∞® Ï∞®Ï¢Ö Î∂ÑÎ•ò</td>
    <td>Solo</td>
    <td>90th / 748 (Top 12%)</td>
    <td><a href="">GitHub</a></td>
  </tr>
</table>

---

### ‚Ä¢ Projects

<table>
  <tr>
    <th>Project</th>
    <th>Description</th>
    <th>Tech Stack</th>
    <th>Links</th>
  </tr>
  <tr>
    <td>Korean Sign Language Recognition</td>
    <td>ÏßÄÎ¨∏Ïûê Ïù∏Ïãù + ÏùåÏÑ± Ïù∏Ïãù ÌÜµÌï© ÏãúÏä§ÌÖú</td>
    <td>MediaPipe, Whisper, PyTorch</td>
    <td><a href="">GitHub</a></td>
  </tr>
  <tr>
    <td>DeZero Framework</td>
    <td>Î∞ëÎ∞îÎã•Î∂ÄÌÑ∞ ÏãúÏûëÌïòÎäî Îî•Îü¨Îãù ÌîÑÎ†àÏûÑÏõåÌÅ¨ (Apple Silicon GPU)</td>
    <td>Python, MLX</td>
    <td><a href="">GitHub</a></td>
  </tr>
  <tr>
    <td>Car Classification</td>
    <td>ConvNeXt Í∏∞Î∞ò Ï∞®Ï¢Ö Î∂ÑÎ•ò (EMA, SWA, TTA)</td>
    <td>PyTorch, timm</td>
    <td><a href="">GitHub</a></td>
  </tr>
</table>

---

### ‚Ä¢ Paper Reading

<table>
  <tr>
    <th>#</th>
    <th>Paper</th>
    <th>Field</th>
    <th>Paper Link</th>
    <th>Notes</th>
  </tr>
  <tr>
    <td>1</td>
    <td>AlexNet</td>
    <td>CNN / Classification</td>
    <td><a href="https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html">NeurIPS 2012</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>2</td>
    <td>VGGNet</td>
    <td>CNN / Classification</td>
    <td><a href="https://arxiv.org/abs/1409.1556">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>3</td>
    <td>ResNet</td>
    <td>CNN / Classification</td>
    <td><a href="https://arxiv.org/abs/1512.03385">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>4</td>
    <td>R-CNN</td>
    <td>Object Detection</td>
    <td><a href="https://arxiv.org/abs/1311.2524">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>5</td>
    <td>Fast R-CNN</td>
    <td>Object Detection</td>
    <td><a href="https://arxiv.org/abs/1504.08083">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>6</td>
    <td>LSTM</td>
    <td>RNN / Sequence</td>
    <td><a href="https://www.bioinf.jku.at/publications/older/2604.pdf">Original</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>7</td>
    <td>XGBoost</td>
    <td>Gradient Boosting</td>
    <td><a href="https://arxiv.org/abs/1603.02754">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>8</td>
    <td>LightGBM</td>
    <td>Gradient Boosting</td>
    <td><a href="https://papers.nips.cc/paper/2017/hash/6449f44a102fde848669bdd9eb6b76fa-Abstract.html">NeurIPS 2017</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>9</td>
    <td>YOLO</td>
    <td>Object Detection</td>
    <td><a href="https://arxiv.org/abs/1506.02640">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>10</td>
    <td>FCN</td>
    <td>Semantic Segmentation</td>
    <td><a href="https://arxiv.org/abs/1411.4038">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>11</td>
    <td>Mask R-CNN</td>
    <td>Instance Segmentation</td>
    <td><a href="https://arxiv.org/abs/1703.06870">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>12</td>
    <td>Panoptic Segmentation</td>
    <td>Panoptic Segmentation</td>
    <td><a href="https://arxiv.org/abs/1801.00868">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>13</td>
    <td>Attention Is All You Need</td>
    <td>Transformer / NLP</td>
    <td><a href="https://arxiv.org/abs/1706.03762">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>14</td>
    <td>Swin Transformer</td>
    <td>Vision Transformer</td>
    <td><a href="https://arxiv.org/abs/2103.14030">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>15</td>
    <td>CLIP</td>
    <td>Vision-Language</td>
    <td><a href="https://arxiv.org/abs/2103.00020">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>16</td>
    <td>SETR</td>
    <td>Transformer Segmentation</td>
    <td><a href="https://arxiv.org/abs/2012.15840">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>17</td>
    <td>Mask2Former</td>
    <td>Universal Segmentation</td>
    <td><a href="https://arxiv.org/abs/2112.01527">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>18</td>
    <td>PointNet++</td>
    <td>3D Point Cloud</td>
    <td><a href="https://arxiv.org/abs/1706.02413">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>19</td>
    <td>RT-1</td>
    <td>Robot VLA</td>
    <td><a href="https://arxiv.org/abs/2212.06817">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>20</td>
    <td>RT-2</td>
    <td>Robot VLA</td>
    <td><a href="https://arxiv.org/abs/2307.15818">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>21</td>
    <td>DINO v1</td>
    <td>Self-Supervised Vision</td>
    <td><a href="https://arxiv.org/abs/2104.14294">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>22</td>
    <td>DINOv2</td>
    <td>Self-Supervised Vision</td>
    <td><a href="https://arxiv.org/abs/2304.07193">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>23</td>
    <td>SAM</td>
    <td>Foundation Model / Segmentation</td>
    <td><a href="https://arxiv.org/abs/2304.02643">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>24</td>
    <td>OpenVLA</td>
    <td>Robot VLA</td>
    <td><a href="https://arxiv.org/abs/2406.09246">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
  <tr>
    <td>25</td>
    <td>Zero-shot RIS with Global-Local Context</td>
    <td>Referring Image Segmentation</td>
    <td><a href="https://arxiv.org/abs/2303.17811">arXiv</a></td>
    <td><a href="https://www.notion.so/2-2d43c05436fc805980edcd1a77ef4007">Notion</a></td>
  </tr>
</table>

---

### ‚Ä¢ OS & Tools üî®

<img src="https://img.shields.io/badge/Linux-FCC624?style=flat-square&logo=linux&logoColor=black"/> <img src="https://img.shields.io/badge/macOS-000000?style=flat-square&logo=apple&logoColor=white"/> <img src="https://img.shields.io/badge/Ubuntu-E95420?style=flat-square&logo=ubuntu&logoColor=white"/>

<img src="https://img.shields.io/badge/Git-F05032?style=flat-square&logo=git&logoColor=white"/> <img src="https://img.shields.io/badge/GitHub-181717?style=flat-square&logo=github&logoColor=white"/>

<img src="https://img.shields.io/badge/PyTorch-EE4C2C?style=flat-square&logo=pytorch&logoColor=white"/> <img src="https://img.shields.io/badge/ü§ó%20Transformers-FFD21E?style=flat-square"/>

<img src="https://img.shields.io/badge/Python-3776AB?style=flat-square&logo=python&logoColor=white"/> <img src="https://img.shields.io/badge/OpenCV-5C3EE8?style=flat-square&logo=opencv&logoColor=white"/>
